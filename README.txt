--------
workflow
--------
1) Have users run get_data.py in all of their toplevel relion directories
2) Run arc_data_analzye.py on the output csv files
3) manually inspect the graphs generated and remove any horrid outliers from useddata.csv
4) Rerun arc_data_analyze.py on useddata.csv (make sure to change its name first)
5) Copy the polynomial factors output by arc_data_analyze.py in queue2.py
6) Put queue2.py, bash_vers.sh, and relion_new_queue.bashrc on arc3


_____________
queue2.py	The main script writes a submission script for arc3 requesting enough time to get the job done as calculate by the models below but without requesting too much, which should speed up execution of jobs in the queue.	

Calculating how much time to use is done with a series of polynomials generated by arc_data_analyze.py script below. It outputs lines 11-13 which can be copied into the script:

	'Refine3D':[5.70156400945e-07, 0.388888018559, 123014.47594],
	'Class3D':[3.37288748034e-06, 0.400375594628, 21750.3592438],
	'Class2D':[-4.05542131513e-07, 0.475747768831, 29222.6171242]
		
The list of nodes can be updated in two sections:
		
	Lines 34-37 define the nodes used for running with automatic and lines 21-24 define the nodes used for running with manual designation of the time requested each line is a single node in teh format:
		
	'cryoem_p100':('cryoEM p100','coproc_p100=4','#$ -P cryoem'),
	     (a)	    (b)            (c)              (d)

	a) node name how user will enter it in the GUI
	b) node name - for recordkeeping
	c) -l argument needed for qsub
	d) any extra lines needed for qsub; separate them with a '\n'
		
		
____________	
bash_vers.sh	The script that relion calls to run queue2.py - shouldn't ever need to be edited.
	

____________
relion_new_queue.bashrc		bashrc writted specifically for arc3.  The environment variables RELION_QSUB_EXTRA1_HELP and RELION_QSUB_EXTRA2_HELP don't seem to work - might be a bug in relion...	


____________
get_data.py	Script that generates data to use for making the runtime models.  Users should run it in each  of their toplevel relion directories.  Currently writes output to: /fbs/emsoftware2/LINUX/fbsmi/scripts/workshop/rln_queuefix/data 
	
	Data are written in /csv format with the following columns:
				
	dir		The directory the script was run in
	jobfile		the run.job file.
	outfile 	the run.out file
	helical 	was the job a helical refinement ('True', 'False', or '0')  0 = False
	nparts		number of particles
	nclasses 	number of classes
	diameter 	diameter of mask
	nprocs		number of MPI processes
	nthreads	number of threads/process
	nodetype	arc3 node type
	lss		value for local angular search
	ias		value for initial angular search
	conti		was the job a continuation
	c3dlas		last iteration specified for 2D/3D classification - used to determin if the job finished
	niter		number if iterations performed total - used to determined if the job finished
	TIME(s)		total time in sec for the job to run
	Finished?	did the job finish?
				
____________				
arc_data_analyze.py	analyzes the data from getdata.py - outputs a file called useddata.csv, which can be used to remove outliers and then run the program again.  USAGE: arc_data_analyze.py <arcdata files>  IE ./arc_data_analyze.py data/arcdata*.csv


